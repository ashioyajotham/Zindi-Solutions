{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9300bef6",
   "metadata": {},
   "source": [
    "# Kenya Clinical Reasoning Challenge\n",
    "\n",
    "This notebook explores and builds a model for the Kenya Clinical Reasoning Challenge, which focuses on predicting clinician responses to medical scenarios in rural Kenyan healthcare settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a8bbcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61be68b",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Let's load the training and testing datasets to begin our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6f5b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (400, 12)\n",
      "Test dataset shape: (100, 7)\n"
     ]
    }
   ],
   "source": [
    "# Load the train and test datasets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Also load the raw versions which may contain additional information\n",
    "train_raw_df = pd.read_csv('train_raw.csv')\n",
    "test_raw_df = pd.read_csv('test_raw.csv')\n",
    "\n",
    "print(f\"Train dataset shape: {train_df.shape}\")\n",
    "print(f\"Test dataset shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0656aca",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Let's examine the structure of our datasets and understand the clinical scenarios better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f8977b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Master_Index</th>\n",
       "      <th>County</th>\n",
       "      <th>Health level</th>\n",
       "      <th>Years of Experience</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Nursing Competency</th>\n",
       "      <th>Clinical Panel</th>\n",
       "      <th>Clinician</th>\n",
       "      <th>GPT4.0</th>\n",
       "      <th>LLAMA</th>\n",
       "      <th>GEMINI</th>\n",
       "      <th>DDX SNOMED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_VBWWP</td>\n",
       "      <td>uasin gishu</td>\n",
       "      <td>sub county hospitals and nursing homes</td>\n",
       "      <td>18.0</td>\n",
       "      <td>i am a nurse with 18 years of experience in ge...</td>\n",
       "      <td>pediatric emergency burns</td>\n",
       "      <td>surgery</td>\n",
       "      <td>summary a 4 year old with 5 superficial burns ...</td>\n",
       "      <td>given your vast experience as a nurse in uasin...</td>\n",
       "      <td>1 immediate treatment protocol for second degr...</td>\n",
       "      <td>here s a response addressing the questions reg...</td>\n",
       "      <td>288514009 burn involving 5 percent of body sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_XMBBY</td>\n",
       "      <td>uasin gishu</td>\n",
       "      <td>national referral hospitals</td>\n",
       "      <td>17.0</td>\n",
       "      <td>i am a nurse with 17 years of experience in ge...</td>\n",
       "      <td>child health</td>\n",
       "      <td>paediatrics</td>\n",
       "      <td>summary 6 year old present with vomiting and a...</td>\n",
       "      <td>clinical summary • a 6 year old girl with know...</td>\n",
       "      <td>based on the symptoms and signs you ve describ...</td>\n",
       "      <td>based on the presentation the 6 year old girl ...</td>\n",
       "      <td>420270002 ketoacidosis due to type 1 diabetes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_JZNZW</td>\n",
       "      <td>kiambu</td>\n",
       "      <td>sub county hospitals and nursing homes</td>\n",
       "      <td>12.0</td>\n",
       "      <td>i am a nurse with 12 years of experience in ge...</td>\n",
       "      <td>general emergency</td>\n",
       "      <td>internal medicine</td>\n",
       "      <td>summary a 47 year old man presents with severe...</td>\n",
       "      <td>in this case you re dealing with a 47 year old...</td>\n",
       "      <td>firstly i must commend you on your thorough hi...</td>\n",
       "      <td>this 47 year old male presenting with severe r...</td>\n",
       "      <td>13200003 peptic ulcer disorder 25458004 acute ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_QOQTK</td>\n",
       "      <td>uasin gishu</td>\n",
       "      <td>national referral hospitals</td>\n",
       "      <td>12.0</td>\n",
       "      <td>i am a nurse with 12 years of experience in pr...</td>\n",
       "      <td>critical care</td>\n",
       "      <td>internal medicine</td>\n",
       "      <td>summary 72 year old female with inability to w...</td>\n",
       "      <td>given er s clinical presentation and vitals th...</td>\n",
       "      <td>to me with this query based on the information...</td>\n",
       "      <td>this 92 year old female patient er presents wi...</td>\n",
       "      <td>14760008 constipation finding 419284004 altere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_ZFJBM</td>\n",
       "      <td>uasin gishu</td>\n",
       "      <td>national referral hospitals</td>\n",
       "      <td>16.0</td>\n",
       "      <td>i am a nurse with 16 years of experience in ge...</td>\n",
       "      <td>adult health</td>\n",
       "      <td>internal medicine</td>\n",
       "      <td>a 22 year old female presents with headache di...</td>\n",
       "      <td>the 22 year old female patient is presenting w...</td>\n",
       "      <td>thank you for presenting this case based on th...</td>\n",
       "      <td>this 22 year old female patient presents with ...</td>\n",
       "      <td>95874006 carbon monoxide poisoning from fire d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Master_Index       County                            Health level  \\\n",
       "0     ID_VBWWP  uasin gishu  sub county hospitals and nursing homes   \n",
       "1     ID_XMBBY  uasin gishu             national referral hospitals   \n",
       "2     ID_JZNZW       kiambu  sub county hospitals and nursing homes   \n",
       "3     ID_QOQTK  uasin gishu             national referral hospitals   \n",
       "4     ID_ZFJBM  uasin gishu             national referral hospitals   \n",
       "\n",
       "   Years of Experience                                             Prompt  \\\n",
       "0                 18.0  i am a nurse with 18 years of experience in ge...   \n",
       "1                 17.0  i am a nurse with 17 years of experience in ge...   \n",
       "2                 12.0  i am a nurse with 12 years of experience in ge...   \n",
       "3                 12.0  i am a nurse with 12 years of experience in pr...   \n",
       "4                 16.0  i am a nurse with 16 years of experience in ge...   \n",
       "\n",
       "          Nursing Competency     Clinical Panel  \\\n",
       "0  pediatric emergency burns            surgery   \n",
       "1               child health        paediatrics   \n",
       "2          general emergency  internal medicine   \n",
       "3              critical care  internal medicine   \n",
       "4               adult health  internal medicine   \n",
       "\n",
       "                                           Clinician  \\\n",
       "0  summary a 4 year old with 5 superficial burns ...   \n",
       "1  summary 6 year old present with vomiting and a...   \n",
       "2  summary a 47 year old man presents with severe...   \n",
       "3  summary 72 year old female with inability to w...   \n",
       "4  a 22 year old female presents with headache di...   \n",
       "\n",
       "                                              GPT4.0  \\\n",
       "0  given your vast experience as a nurse in uasin...   \n",
       "1  clinical summary • a 6 year old girl with know...   \n",
       "2  in this case you re dealing with a 47 year old...   \n",
       "3  given er s clinical presentation and vitals th...   \n",
       "4  the 22 year old female patient is presenting w...   \n",
       "\n",
       "                                               LLAMA  \\\n",
       "0  1 immediate treatment protocol for second degr...   \n",
       "1  based on the symptoms and signs you ve describ...   \n",
       "2  firstly i must commend you on your thorough hi...   \n",
       "3  to me with this query based on the information...   \n",
       "4  thank you for presenting this case based on th...   \n",
       "\n",
       "                                              GEMINI  \\\n",
       "0  here s a response addressing the questions reg...   \n",
       "1  based on the presentation the 6 year old girl ...   \n",
       "2  this 47 year old male presenting with severe r...   \n",
       "3  this 92 year old female patient er presents wi...   \n",
       "4  this 22 year old female patient presents with ...   \n",
       "\n",
       "                                          DDX SNOMED  \n",
       "0  288514009 burn involving 5 percent of body sur...  \n",
       "1  420270002 ketoacidosis due to type 1 diabetes ...  \n",
       "2  13200003 peptic ulcer disorder 25458004 acute ...  \n",
       "3  14760008 constipation finding 419284004 altere...  \n",
       "4  95874006 carbon monoxide poisoning from fire d...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the training data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8072a4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset columns:\n",
      "['Master_Index', 'County', 'Health level', 'Years of Experience', 'Prompt', 'Nursing Competency', 'Clinical Panel', 'Clinician', 'GPT4.0', 'LLAMA', 'GEMINI', 'DDX SNOMED']\n",
      "\n",
      "Test dataset columns:\n",
      "['Master_Index', 'County', 'Health level', 'Years of Experience', 'Prompt', 'Nursing Competency', 'Clinical Panel']\n"
     ]
    }
   ],
   "source": [
    "# Check for columns in the training set\n",
    "print(\"Train dataset columns:\")\n",
    "print(train_df.columns.tolist())\n",
    "\n",
    "print(\"\\nTest dataset columns:\")\n",
    "print(test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06dd83e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train dataset:\n",
      "Master_Index             0\n",
      "County                   0\n",
      "Health level             0\n",
      "Years of Experience    100\n",
      "Prompt                   0\n",
      "Nursing Competency       0\n",
      "Clinical Panel           0\n",
      "Clinician                0\n",
      "GPT4.0                   0\n",
      "LLAMA                    0\n",
      "GEMINI                   0\n",
      "DDX SNOMED               1\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test dataset:\n",
      "Master_Index            0\n",
      "County                  0\n",
      "Health level            0\n",
      "Years of Experience    25\n",
      "Prompt                  0\n",
      "Nursing Competency      0\n",
      "Clinical Panel          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in train dataset:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in test dataset:\")\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65758bd3",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Based on the challenge description, we need to transform the clinician responses according to specific rules:\n",
    "1. Deal with missing values\n",
    "2. Convert all text to lowercase\n",
    "3. Remove punctuation\n",
    "4. Replace paragraphs with spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009be291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample clinician column before cleaning:\n",
      "summary a 4 year old with 5 superficial burns no other injuries immediate management paracetamol analgesics to to ensure child has minimal or no pain cleaning and frosting of wound with silver sulpha fizika topical prophylactic can be considered in this case good nutrition high protein diet\n",
      "\n",
      "---\n",
      "\n",
      "Sample clinician column after cleaning:\n",
      "immediate management paracetamol analgesics to to ensure child has minimal or no pain cleaning and frosting of wound with silver sulpha fizika topical prophylactic can be considered in this case good nutrition high protein diet\n",
      "\n",
      "---\n",
      "\n",
      "Number of clinician responses that started with 'summary': 316 out of 400\n"
     ]
    }
   ],
   "source": [
    "# Dealing with missing values\n",
    "# Years of experience column has some missing values, let's fill them with the mean\n",
    "train_df['Years of Experience'].fillna(train_df['Years of Experience'].mean(), inplace=True)    \n",
    "test_df['Years of Experience'].fillna(test_df['Years of Experience'].mean(), inplace=True)\n",
    "\n",
    "# DDX SNOMED column has some missing values, let's fill them with the mode\n",
    "train_df['DDX SNOMED'].fillna(train_df['DDX SNOMED'].mode()[0], inplace=True)\n",
    "\n",
    "# Clean up the 'Clinician' column by removing the \"summary\" prefix\n",
    "def clean_summary_prefix(text):\n",
    "    \"\"\"Remove 'summary' and redundant text from the beginning of clinician responses\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    # Check if the text starts with 'summary'\n",
    "    text = text.lower().strip()\n",
    "    if text.startswith('summary'):\n",
    "        # Find where the actual content begins after the case summary\n",
    "        # Typically after details about the patient, symptoms, vitals, etc.\n",
    "        \n",
    "        # Look for common transition points where the actual medical advice begins\n",
    "        content_markers = [\n",
    "            'diagnosis:', 'diagnosis', 'management:', 'management',\n",
    "            'treatment:', 'treatment', 'plan:', 'plan',\n",
    "            'investigations:', 'investigations', 'ddx', 'differentials:',\n",
    "            'immediate management', 'how to manage'\n",
    "        ]\n",
    "        \n",
    "        # First, try to find the position of any content markers\n",
    "        positions = [text.find(marker) for marker in content_markers if text.find(marker) > 0]\n",
    "        \n",
    "        if positions:\n",
    "            # Find the earliest marker position\n",
    "            start_pos = min(positions)\n",
    "            return text[start_pos:].strip()\n",
    "        else:\n",
    "            # If no marker is found, check for end of patient description\n",
    "            # This typically contains age, vitals, symptoms in the summary\n",
    "            # Often ends with phrases like 'vitals are normal', 'temp', 'bp', etc.\n",
    "            vital_markers = ['vitals', 'bp', 'temp', 'pulse', 'spo2', 'vital signs']\n",
    "            vital_positions = []\n",
    "            \n",
    "            # Find the last mention of vitals\n",
    "            for marker in vital_markers:\n",
    "                pos = text.rfind(marker, 0, len(text)//2)  # Search in the first half\n",
    "                if pos > 0:\n",
    "                    vital_positions.append(pos)\n",
    "            \n",
    "            if vital_positions:\n",
    "                # Find where the vital signs description likely ends\n",
    "                vital_pos = max(vital_positions)\n",
    "                end_of_vitals = text.find('.', vital_pos)\n",
    "                if end_of_vitals > 0:\n",
    "                    return text[end_of_vitals + 1:].strip()\n",
    "            \n",
    "            # Last resort: look for a question that might start the clinical response\n",
    "            questions = ['what ', 'how ', 'why ', 'when ', 'which ', 'is ', 'are ', 'can ', 'should ']\n",
    "            for q in questions:\n",
    "                q_pos = text.find(q, len('summary') + 5)  # Search after 'summary' + some buffer\n",
    "                if q_pos > 0:\n",
    "                    # Find the beginning of the sentence containing the question\n",
    "                    sentence_start = text.rfind('. ', 0, q_pos)\n",
    "                    if sentence_start > 0:\n",
    "                        return text[sentence_start + 2:].strip()\n",
    "                    else:\n",
    "                        return text[q_pos:].strip()\n",
    "            \n",
    "            # If all else fails, just remove 'summary' and a bit after it\n",
    "            return text[len('summary') + 2:].strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the Clinician column\n",
    "print(\"Sample clinician column before cleaning:\")\n",
    "print(train_df['Clinician'].iloc[0])\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "train_df['Clinician'] = train_df['Clinician'].apply(clean_summary_prefix)\n",
    "\n",
    "print(\"Sample clinician column after cleaning:\")\n",
    "print(train_df['Clinician'].iloc[0])\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "# Check how many rows had the 'summary' prefix\n",
    "original_texts = pd.read_csv('train.csv')['Clinician']\n",
    "summary_count = sum(1 for text in original_texts if str(text).lower().strip().startswith('summary'))\n",
    "print(f\"Number of clinician responses that started with 'summary': {summary_count} out of {len(train_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f7626bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows in train dataset:\n",
      "0\n",
      "\n",
      "Duplicate rows in test dataset:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(\"Duplicate rows in train dataset:\")\n",
    "print(train_df.duplicated().sum())\n",
    "\n",
    "print(\"\\nDuplicate rows in test dataset:\")\n",
    "print(test_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4154f799",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Let's create features that will help our model understand the clinical scenarios better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40f90481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK resources downloaded successfully\n",
      "\n",
      "Training data with new features:\n",
      "   Patient_Age Patient_Gender  Is_Pediatric  Is_Emergency Experience_Level  \\\n",
      "0          4.0        Unknown          True          True           Expert   \n",
      "1          6.0         Female          True          True           Expert   \n",
      "2          NaN           Male         False         False           Senior   \n",
      "3          NaN         Female         False          True           Senior   \n",
      "4         22.0         Female         False         False           Expert   \n",
      "\n",
      "   Facility_Complexity  \n",
      "0                    2  \n",
      "1                    3  \n",
      "2                    2  \n",
      "3                    3  \n",
      "4                    3  \n",
      "\n",
      "Total features in training data: 166\n",
      "Total features in test data: 161\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    print(\"NLTK resources downloaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading NLTK resources: {e}\")\n",
    "\n",
    "# 1. Create nurse experience/seniority categories\n",
    "def categorize_experience(years):\n",
    "    \"\"\"Categorize years of experience into seniority levels.\"\"\"\n",
    "    if years < 5:\n",
    "        return 'Junior'\n",
    "    elif years < 10:\n",
    "        return 'Intermediate'\n",
    "    elif years < 15:\n",
    "        return 'Senior'\n",
    "    else:\n",
    "        return 'Expert'\n",
    "\n",
    "# Apply to both datasets\n",
    "train_df['Experience_Level'] = train_df['Years of Experience'].apply(categorize_experience)\n",
    "test_df['Experience_Level'] = test_df['Years of Experience'].apply(categorize_experience)\n",
    "\n",
    "# 2. Extract patient demographics from prompts\n",
    "def extract_patient_demographics(text):\n",
    "    \"\"\"Extract patient age, gender, and other key demographics from prompt text.\"\"\"\n",
    "    demographics = {}\n",
    "    \n",
    "    # Extract age\n",
    "    age_pattern = r'(\\d+)[ -](?:year|yr)[ -]old'\n",
    "    age_match = re.search(age_pattern, text.lower())\n",
    "    if age_match:\n",
    "        demographics['age'] = int(age_match.group(1))\n",
    "    else:\n",
    "        demographics['age'] = None\n",
    "    \n",
    "    # Extract gender\n",
    "    if re.search(r'\\b(male|man|boy|he|him)\\b', text.lower()):\n",
    "        demographics['gender'] = 'Male'\n",
    "    elif re.search(r'\\b(female|woman|girl|she|her)\\b', text.lower()):\n",
    "        demographics['gender'] = 'Female'\n",
    "    else:\n",
    "        demographics['gender'] = 'Unknown'\n",
    "    \n",
    "    # Pediatric vs Adult\n",
    "    demographics['is_pediatric'] = False\n",
    "    if 'age' in demographics and demographics['age'] is not None:\n",
    "        if demographics['age'] < 18:\n",
    "            demographics['is_pediatric'] = True\n",
    "    elif re.search(r'\\b(child|infant|baby|toddler|newborn)\\b', text.lower()):\n",
    "        demographics['is_pediatric'] = True\n",
    "    \n",
    "    # Extract if emergency\n",
    "    demographics['is_emergency'] = bool(re.search(r'\\b(emergency|urgent|critical|immediately|collapse)\\b', text.lower()))\n",
    "    \n",
    "    return demographics\n",
    "\n",
    "# Apply to both datasets\n",
    "train_demographics = train_df['Prompt'].apply(extract_patient_demographics)\n",
    "test_demographics = test_df['Prompt'].apply(extract_patient_demographics)\n",
    "\n",
    "# Convert the dictionaries to dataframe columns\n",
    "train_df['Patient_Age'] = train_demographics.apply(lambda x: x['age'])\n",
    "train_df['Patient_Gender'] = train_demographics.apply(lambda x: x['gender'])\n",
    "train_df['Is_Pediatric'] = train_demographics.apply(lambda x: x['is_pediatric'])\n",
    "train_df['Is_Emergency'] = train_demographics.apply(lambda x: x['is_emergency'])\n",
    "\n",
    "test_df['Patient_Age'] = test_demographics.apply(lambda x: x['age'])\n",
    "test_df['Patient_Gender'] = test_demographics.apply(lambda x: x['gender'])\n",
    "test_df['Is_Pediatric'] = test_demographics.apply(lambda x: x['is_pediatric'])\n",
    "test_df['Is_Emergency'] = test_demographics.apply(lambda x: x['is_emergency'])\n",
    "\n",
    "# 3. Extract symptoms and conditions (medical NLP features)\n",
    "def extract_medical_keywords(text):\n",
    "    \"\"\"Extract key medical terms from the prompt.\"\"\"\n",
    "    # Common symptoms and conditions to look for\n",
    "    keywords = [\n",
    "        'fever', 'pain', 'cough', 'headache', 'nausea', 'vomiting', 'diarrhea',\n",
    "        'bleeding', 'swelling', 'rash', 'fatigue', 'weakness', 'difficulty breathing',\n",
    "        'hypertension', 'diabetes', 'asthma', 'hiv', 'tuberculosis', 'malaria',\n",
    "        'pneumonia', 'wound', 'injury', 'fracture', 'burn', 'infection'\n",
    "    ]\n",
    "    \n",
    "    found_keywords = []\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        if keyword in text_lower:\n",
    "            found_keywords.append(keyword)\n",
    "    \n",
    "    return found_keywords\n",
    "\n",
    "# Apply to both datasets\n",
    "train_df['Medical_Keywords'] = train_df['Prompt'].apply(extract_medical_keywords)\n",
    "test_df['Medical_Keywords'] = test_df['Prompt'].apply(extract_medical_keywords)\n",
    "\n",
    "# Create binary features for important medical conditions\n",
    "for condition in ['fever', 'pain', 'cough', 'bleeding', 'hypertension', 'diabetes']:\n",
    "    train_df[f'Has_{condition.capitalize()}'] = train_df['Medical_Keywords'].apply(lambda x: condition in x)\n",
    "    test_df[f'Has_{condition.capitalize()}'] = test_df['Medical_Keywords'].apply(lambda x: condition in x)\n",
    "\n",
    "# 4. Hospital level complexity (higher level facilities can handle more complex cases)\n",
    "def hospital_complexity(facility_type):\n",
    "    \"\"\"Assign a complexity score based on health facility level.\"\"\"\n",
    "    facility_type = facility_type.lower()\n",
    "    if 'national referral' in facility_type:\n",
    "        return 3  # Highest complexity\n",
    "    elif 'sub-county' in facility_type or 'sub county' in facility_type:\n",
    "        return 2  # Medium complexity\n",
    "    elif 'health centres' in facility_type or 'health center' in facility_type:\n",
    "        return 1\n",
    "    else:  # Dispensaries, private clinics\n",
    "        return 0  # Basic care\n",
    "\n",
    "train_df['Facility_Complexity'] = train_df['Health level'].apply(hospital_complexity)\n",
    "test_df['Facility_Complexity'] = test_df['Health level'].apply(hospital_complexity)\n",
    "\n",
    "# Display the data with new features\n",
    "print(\"\\nTraining data with new features:\")\n",
    "print(train_df[['Patient_Age', 'Patient_Gender', 'Is_Pediatric', 'Is_Emergency', 'Experience_Level', 'Facility_Complexity']].head())\n",
    "\n",
    "# 5. One-hot encode categorical features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_features = ['Experience_Level', 'Patient_Gender', 'Nursing Competency', 'Clinical Panel']\n",
    "for feature in categorical_features:\n",
    "    if feature in train_df.columns and feature in test_df.columns:\n",
    "        # Get all unique values from both train and test\n",
    "        unique_values = list(set(train_df[feature].unique()) | set(test_df[feature].unique()))\n",
    "        \n",
    "        # Create binary columns for each category\n",
    "        for value in unique_values:\n",
    "            column_name = f\"{feature}_{value}\"\n",
    "            train_df[column_name] = (train_df[feature] == value).astype(int)\n",
    "            test_df[column_name] = (test_df[feature] == value).astype(int)\n",
    "\n",
    "# 6. Text embeddings using TF-IDF\n",
    "# We'll use this to capture the semantic meaning of prompts\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=100,  # Limit number of features to avoid dimensionality issues\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2)  # Include both unigrams and bigrams\n",
    ")\n",
    "\n",
    "# Fit on combined train and test prompts to ensure consistent vocabulary\n",
    "all_prompts = list(train_df['Prompt']) + list(test_df['Prompt'])\n",
    "vectorizer.fit(all_prompts)\n",
    "\n",
    "# Transform train and test sets\n",
    "train_tfidf = vectorizer.transform(train_df['Prompt'])\n",
    "test_tfidf = vectorizer.transform(test_df['Prompt'])\n",
    "\n",
    "# Convert to DataFrame and add as new columns\n",
    "tfidf_feature_names = vectorizer.get_feature_names_out()\n",
    "train_tfidf_df = pd.DataFrame(train_tfidf.toarray(), columns=[f'tfidf_{name}' for name in tfidf_feature_names])\n",
    "test_tfidf_df = pd.DataFrame(test_tfidf.toarray(), columns=[f'tfidf_{name}' for name in tfidf_feature_names])\n",
    "\n",
    "# Join with main dataframes\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), train_tfidf_df], axis=1)\n",
    "test_df = pd.concat([test_df.reset_index(drop=True), test_tfidf_df], axis=1)\n",
    "\n",
    "# Show the size of our feature set\n",
    "print(f\"\\nTotal features in training data: {train_df.shape[1]}\")\n",
    "print(f\"Total features in test data: {test_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55a72cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can viz some patterns eg patient age, age distribution\n",
    "# But first let's fill missing values in the patient age column\n",
    "train_df['Patient_Age'].fillna(train_df['Patient_Age'].mean(), inplace=True)\n",
    "\n",
    "test_df['Patient_Age'].fillna(test_df['Patient_Age'].mean(), inplace=True)\n",
    "\n",
    "# Plotting age distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['Patient_Age'], bins=30, kde=True, color='blue', alpha=0.6)\n",
    "plt.title('Age Distribution in Training Data')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6668819",
   "metadata": {},
   "source": [
    "## Model Development\n",
    "\n",
    "We'll use NLP techniques to predict clinician responses. The ROUGE Score is mentioned as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "442d56e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error splitting data: name 'train_test_split' is not defined\n",
      "Please adjust based on the actual data structure.\n"
     ]
    }
   ],
   "source": [
    "# Let's split the data for training and validation\n",
    "try:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(\"Data split successful.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error splitting data: {e}\")\n",
    "    print(\"Please adjust based on the actual data structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdf53bf",
   "metadata": {},
   "source": [
    "## NLP Model Using Transformer-based Approaches\n",
    "\n",
    "Since this is a text-to-text generation task, we'll use a transformer-based model to predict clinician responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0c0debd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.47.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: evaluate in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: rouge-score in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: accelerate in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\homepc\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: click in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\homepc\\appdata\\roaming\\python\\python311\\site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\homepc\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\homepc\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: networkx in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\homepc\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\homepc\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\homepc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries if not already installed\n",
    "!pip install transformers datasets evaluate nltk rouge-score accelerate scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b9b3843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Error loading model: Failed to import transformers.models.t5.modeling_t5 because of the following error (look up to see its traceback):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HomePC\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "See https://www.tensorflow.org/install/errors for some common causes and solutions.\n",
      "If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.\n",
      "Consider trying a different model or approach.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rouge_score import rouge_scorer\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Force PyTorch as the backend and disable TensorFlow\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"\n",
    "os.environ[\"USE_TORCH\"] = \"1\" \n",
    "os.environ[\"USE_TF\"] = \"0\"\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize a pretrained model\n",
    "try:\n",
    "    # Option 1: Medical-specific model\n",
    "    # model_name = \"GanjinZero/biobart-v2-base\"\n",
    "    \n",
    "    # Option 2: General-purpose model with good performance on instruction-following tasks\n",
    "    model_name = \"google/flan-t5-base\"\n",
    "    \n",
    "    print(f\"Loading {model_name} model and tokenizer...\")\n",
    "    \n",
    "    # Initialize tokenizer with explicit use_fast=True to avoid TF dependencies\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    \n",
    "    # Load model with torch_dtype for potential memory savings\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float32,  # Use float16 if you have GPU to save memory\n",
    "        device_map=device\n",
    "    )\n",
    "    \n",
    "    print(f\"Successfully loaded {model_name} model\")\n",
    "    \n",
    "    # Test a simple inference to confirm everything works\n",
    "    input_text = \"Translate to French: Hello, how are you?\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_length=50)\n",
    "    print(f\"Test output: {tokenizer.decode(outputs[0], skip_special_tokens=True)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"Stack trace:\", file=sys.stderr)\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"\\nConsider trying a different model or approach.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178245fb",
   "metadata": {},
   "source": [
    "## Prepare Training Data\n",
    "\n",
    "We'll create a custom training dataset by combining the prompt with the engineered features to create a comprehensive input for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b6605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_for_model(row, include_features=True):\n",
    "    \"\"\"Prepare a comprehensive input for the model by combining the prompt with key features.\"\"\"\n",
    "    prompt = row['Prompt']\n",
    "    \n",
    "    # If we want to include engineered features\n",
    "    if include_features:\n",
    "        # Add key demographic information\n",
    "        features = []\n",
    "        \n",
    "        # Add patient age if available\n",
    "        if not pd.isna(row['Patient_Age']):\n",
    "            features.append(f\"Patient age: {int(row['Patient_Age'])}\")\n",
    "            \n",
    "        # Add patient gender\n",
    "        features.append(f\"Patient gender: {row['Patient_Gender']}\")\n",
    "        \n",
    "        # Add facility complexity\n",
    "        facility_levels = {0: 'Basic', 1: 'Medium', 2: 'High', 3: 'Very High'}\n",
    "        features.append(f\"Facility level: {facility_levels.get(row['Facility_Complexity'], 'Unknown')}\")\n",
    "        \n",
    "        # Add medical keywords if present\n",
    "        if len(row['Medical_Keywords']) > 0:\n",
    "            features.append(f\"Key conditions: {', '.join(row['Medical_Keywords'])}\")\n",
    "            \n",
    "        # Combine features with the original prompt\n",
    "        if features:\n",
    "            feature_text = \"\\n\".join(features)\n",
    "            enhanced_prompt = f\"{prompt}\\n\\nAdditional context:\\n{feature_text}\\n\\nProvide a detailed clinical reasoning and management plan:\"\n",
    "            return enhanced_prompt\n",
    "        \n",
    "    return f\"{prompt}\\n\\nProvide a detailed clinical reasoning and management plan:\"\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_inputs, val_inputs, train_targets, val_targets = train_test_split(\n",
    "    train_df,\n",
    "    train_df['Clinician'],\n",
    "    test_size=0.15,  # Using 15% as validation\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Prepare the enhanced inputs\n",
    "train_enhanced_inputs = [prepare_input_for_model(row) for _, row in train_inputs.iterrows()]\n",
    "val_enhanced_inputs = [prepare_input_for_model(row) for _, row in val_inputs.iterrows()]\n",
    "\n",
    "print(f\"Training samples: {len(train_enhanced_inputs)}\")\n",
    "print(f\"Validation samples: {len(val_enhanced_inputs)}\")\n",
    "\n",
    "# Print an example of the enhanced input\n",
    "print(\"\\nExample of enhanced input:\")\n",
    "print(\"-\" * 80)\n",
    "print(train_enhanced_inputs[0][:500] + \"...\" if len(train_enhanced_inputs[0]) > 500 else train_enhanced_inputs[0])\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nTarget output:\")\n",
    "print(\"-\" * 80)\n",
    "print(train_targets.iloc[0][:500] + \"...\" if len(train_targets.iloc[0]) > 500 else train_targets.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2458378c",
   "metadata": {},
   "source": [
    "## Create Datasets for Transformer Model\n",
    "\n",
    "Now we'll format our data for the Hugging Face transformer library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31977300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transformer_dataset(inputs, targets, tokenizer, max_length=512):\n",
    "    \"\"\"Create a dataset compatible with the Hugging Face trainer.\"\"\"\n",
    "    # Create a dictionary with inputs and targets\n",
    "    dataset_dict = {\n",
    "        'input': inputs,\n",
    "        'target': targets\n",
    "    }\n",
    "    \n",
    "    # Convert to Dataset object\n",
    "    dataset = Dataset.from_dict(dataset_dict)\n",
    "    \n",
    "    # Define tokenization function\n",
    "    def tokenize_function(examples):\n",
    "        # Tokenize inputs\n",
    "        model_inputs = tokenizer(\n",
    "            examples['input'],\n",
    "            max_length=max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        \n",
    "        # Tokenize targets\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(\n",
    "                examples['target'],\n",
    "                max_length=max_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "            )\n",
    "        \n",
    "        # Replace padding token id with -100 for loss calculation\n",
    "        model_inputs[\"labels\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label]\n",
    "            for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "        \n",
    "        return model_inputs\n",
    "    \n",
    "    # Apply tokenization\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "    return tokenized_dataset\n",
    "\n",
    "# Create datasets\n",
    "try:\n",
    "    # Set up tokenizer for padding\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Add special handling for target tokenization\n",
    "    tokenizer.add_special_tokens({'additional_special_tokens': ['<target>']}) \n",
    "    \n",
    "    # Convert all targets to strings in case they aren't already\n",
    "    train_targets_list = [str(target) for target in train_targets.tolist()]\n",
    "    val_targets_list = [str(target) for target in val_targets.tolist()]\n",
    "    \n",
    "    # Create tokenized datasets\n",
    "    train_dataset = create_transformer_dataset(train_enhanced_inputs, train_targets_list, tokenizer)\n",
    "    val_dataset = create_transformer_dataset(val_enhanced_inputs, val_targets_list, tokenizer)\n",
    "    \n",
    "    print(f\"Created train dataset with {len(train_dataset)} samples\")\n",
    "    print(f\"Created validation dataset with {len(val_dataset)} samples\")\n",
    "    \n",
    "    # Show dataset format\n",
    "    print(\"\\nSample features in the dataset:\")\n",
    "    print(list(train_dataset.features.keys()))\n",
    "except Exception as e:\n",
    "    print(f\"Error creating datasets: {e}\")\n",
    "    print(\"Attempting alternative approach...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4607c6c5",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "Now we'll set up and run the training process using the Hugging Face Trainer API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9c2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Calculate ROUGE scores for evaluation.\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Decode predictions\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 with pad token id to properly decode labels\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Compute ROUGE scores\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    \n",
    "    # Filter out columns with '*' to keep the output clean\n",
    "    result = {k: round(v * 100, 2) for k, v in result.items() if '*' not in k}\n",
    "    return result\n",
    "\n",
    "# Set up data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "# Define training arguments - FIXED VERSION\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./kenya_clinical_model\",\n",
    "    # Essential for EarlyStoppingCallback\n",
    "    evaluation_strategy=\"steps\",  # Must be either steps or epoch for EarlyStoppingCallback\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",        # Must match evaluation_strategy\n",
    "    save_steps=50,                # Must be a multiple of eval_steps\n",
    "    load_best_model_at_end=True,  # Required to load the best model at the end of training\n",
    "    metric_for_best_model=\"rouge1\", # Required for EarlyStoppingCallback\n",
    "    greater_is_better=True,       # For ROUGE scores, higher is better\n",
    "    # Other training parameters\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    gradient_accumulation_steps=4,\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")\n",
    "\n",
    "# Run the training (uncomment to execute)\n",
    "print(\"Training ready to start.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184a7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a864e",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "\n",
    "Let's evaluate our trained model on the validation set and visualize some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df2294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, validation_inputs, validation_targets, num_examples=5):\n",
    "    \"\"\"Evaluate the model and show examples of predictions.\"\"\"\n",
    "    # Initialize ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # Generate predictions for each validation example\n",
    "    predictions = []\n",
    "    \n",
    "    for input_text in validation_inputs[:num_examples]:\n",
    "        # Tokenize the input\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "        \n",
    "        # Generate prediction\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                inputs.input_ids,\n",
    "                max_length=256,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        # Decode the output\n",
    "        prediction = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    # Calculate average ROUGE scores\n",
    "    scores = {'rouge1': 0, 'rouge2': 0, 'rougeL': 0}\n",
    "    \n",
    "    for i, (pred, ref) in enumerate(zip(predictions, validation_targets[:num_examples])):\n",
    "        # Display example\n",
    "        print(f\"\\nExample {i+1}:\\n{'-' * 40}\")\n",
    "        print(f\"Input:\\n{validation_inputs[i][:150]}...\")\n",
    "        print(f\"\\nReference:\\n{ref[:150]}...\")\n",
    "        print(f\"\\nPrediction:\\n{pred[:150]}...\")\n",
    "        \n",
    "        # Calculate scores\n",
    "        score = scorer.score(pred, ref)\n",
    "        \n",
    "        # Update running totals\n",
    "        scores['rouge1'] += score['rouge1'].fmeasure\n",
    "        scores['rouge2'] += score['rouge2'].fmeasure\n",
    "        scores['rougeL'] += score['rougeL'].fmeasure\n",
    "        \n",
    "        print(f\"\\nROUGE Scores:\")\n",
    "        print(f\"ROUGE-1: {score['rouge1'].fmeasure:.4f}\")\n",
    "        print(f\"ROUGE-2: {score['rouge2'].fmeasure:.4f}\")\n",
    "        print(f\"ROUGE-L: {score['rougeL'].fmeasure:.4f}\")\n",
    "    \n",
    "    # Calculate averages\n",
    "    for key in scores:\n",
    "        scores[key] /= num_examples\n",
    "    \n",
    "    print(f\"\\nAverage ROUGE Scores across {num_examples} examples:\")\n",
    "    print(f\"ROUGE-1: {scores['rouge1']:.4f}\")\n",
    "    print(f\"ROUGE-2: {scores['rouge2']:.4f}\")\n",
    "    print(f\"ROUGE-L: {scores['rougeL']:.4f}\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Uncomment to evaluate the model after training\n",
    "# print(\"Evaluating model on sample validation examples...\")\n",
    "# eval_scores = evaluate_model(model, val_enhanced_inputs, val_targets_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e4afef",
   "metadata": {},
   "source": [
    "## Generate Final Predictions for Test Set\n",
    "\n",
    "Now let's generate predictions for the test set using our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202897e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_predictions(model, test_df):\n",
    "    \"\"\"Generate predictions for the test set.\"\"\"\n",
    "    print(\"Generating predictions for test set...\")\n",
    "    \n",
    "    predictions = []\n",
    "    ids = []\n",
    "    \n",
    "    for idx, row in test_df.iterrows():\n",
    "        # Prepare input with the same preprocessing as training data\n",
    "        input_text = prepare_input_for_model(row)\n",
    "        \n",
    "        # Tokenize the input\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "        \n",
    "        # Generate prediction\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                inputs.input_ids,\n",
    "                max_length=256,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        # Decode the output\n",
    "        prediction = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Process according to challenge requirements (lowercase, remove punctuation, etc.)\n",
    "        prediction = preprocess_clinical_text(prediction)\n",
    "        \n",
    "        # Save prediction and ID\n",
    "        predictions.append(prediction)\n",
    "        ids.append(row['Master_Index'])\n",
    "        \n",
    "        # Progress update\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"Generated {idx + 1}/{len(test_df)} predictions\")\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'Master_Index': ids,\n",
    "        'Clinician': predictions\n",
    "    })\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "# Uncomment to generate predictions after training\n",
    "# submission_df = generate_test_predictions(model, test_df)\n",
    "# submission_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332231ee",
   "metadata": {},
   "source": [
    "## Save Submission File\n",
    "\n",
    "Finally, let's save our predictions to a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8635b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(submission_df, filename=\"kenya_clinical_submission.csv\"):\n",
    "    \"\"\"Save the submission DataFrame to a CSV file.\"\"\"\n",
    "    # Ensure columns match the sample submission format\n",
    "    sample_submission = pd.read_csv('SampleSubmission.csv')\n",
    "    required_columns = sample_submission.columns.tolist()\n",
    "    \n",
    "    # Check if columns match\n",
    "    if set(submission_df.columns) != set(required_columns):\n",
    "        print(f\"Warning: Submission columns {submission_df.columns.tolist()} don't match required columns {required_columns}\")\n",
    "    \n",
    "    # Save the file\n",
    "    submission_df.to_csv(filename, index=False)\n",
    "    print(f\"Submission saved to {filename}\")\n",
    "    \n",
    "    # Show first few rows\n",
    "    print(\"\\nFirst rows of submission file:\")\n",
    "    print(submission_df.head())\n",
    "\n",
    "# Uncomment to save submission after generating predictions\n",
    "# save_submission(submission_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0871bdea",
   "metadata": {},
   "source": [
    "## Alternative Approach: Simple Sequence-to-Sequence with LSTM\n",
    "\n",
    "If you want a simpler and potentially faster approach, you can also try an LSTM-based sequence-to-sequence model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b35924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple_lstm_approach():\n",
    "    \"\"\"Train a simpler LSTM-based model as an alternative approach.\"\"\"\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    \n",
    "    # Prepare the data\n",
    "    train_inputs = [prepare_input_for_model(row, include_features=False) for _, row in train_inputs_df.iterrows()]\n",
    "    train_targets = train_targets_df.tolist()\n",
    "    \n",
    "    # Create tokenizers\n",
    "    input_tokenizer = Tokenizer(num_words=15000, oov_token=\"<OOV>\")\n",
    "    input_tokenizer.fit_on_texts(train_inputs)\n",
    "    target_tokenizer = Tokenizer(num_words=15000, oov_token=\"<OOV>\") \n",
    "    target_tokenizer.fit_on_texts(train_targets)\n",
    "    \n",
    "    # Convert to sequences\n",
    "    input_sequences = input_tokenizer.texts_to_sequences(train_inputs)\n",
    "    target_sequences = target_tokenizer.texts_to_sequences(train_targets)\n",
    "    \n",
    "    # Pad sequences\n",
    "    max_input_len = 300\n",
    "    max_target_len = 300\n",
    "    input_padded = pad_sequences(input_sequences, maxlen=max_input_len, padding='post')\n",
    "    target_padded = pad_sequences(target_sequences, maxlen=max_target_len, padding='post')\n",
    "    \n",
    "    # Define model\n",
    "    embedding_dim = 256\n",
    "    lstm_units = 256\n",
    "    \n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(max_input_len,))\n",
    "    encoder_embedding = Embedding(15000, embedding_dim)(encoder_inputs)\n",
    "    encoder_lstm = LSTM(lstm_units, return_state=True)\n",
    "    _, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(max_target_len,))\n",
    "    decoder_embedding = Embedding(15000, embedding_dim)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(15000, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    \n",
    "    # Prepare decoder input data (with start token)\n",
    "    decoder_input_data = np.zeros_like(target_padded)\n",
    "    decoder_input_data[:, 1:] = target_padded[:, :-1]\n",
    "    decoder_input_data[:, 0] = target_tokenizer.word_index['<OOV>']\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        [input_padded, decoder_input_data],\n",
    "        target_padded,\n",
    "        batch_size=64,\n",
    "        epochs=10,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    # Save the model and tokenizers\n",
    "    model.save('simple_lstm_model')\n",
    "    \n",
    "    return model, input_tokenizer, target_tokenizer\n",
    "\n",
    "# Uncomment to try the simple LSTM approach\n",
    "# try:\n",
    "#     print(\"Training simple LSTM model as an alternative...\")\n",
    "#     lstm_model, input_tokenizer, target_tokenizer = train_simple_lstm_approach()\n",
    "# except Exception as e:\n",
    "#     print(f\"Error training LSTM model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13713aa",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We've now built a complete pipeline for training and evaluating models for the Kenya Clinical Reasoning Challenge:\n",
    "\n",
    "1. Created enhanced inputs with our engineered features\n",
    "2. Prepared datasets for transformer-based models\n",
    "3. Set up a training pipeline with appropriate evaluation metrics (ROUGE scores)\n",
    "4. Built code for evaluating the model and generating final predictions\n",
    "5. Added an alternative LSTM-based approach\n",
    "\n",
    "To improve performance further, consider:\n",
    "- Trying different pretrained models, especially ones fine-tuned for medical text\n",
    "- Experimenting with different prompt formats and feature combinations\n",
    "- Applying additional text cleaning to the targets\n",
    "- Using ensemble methods to combine predictions from multiple models\n",
    "- Expanding the training data with augmentation techniques\n",
    "\n",
    "The full pipeline is now ready to be executed. Uncomment the training lines to begin training, then evaluate and generate your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
